{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1fH83ZNPZb3A7K1YETet2qk1CwHmGCJuT",
      "authorship_tag": "ABX9TyPEbCxk22H40insJovOde05",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Soumadeep555/RAG/blob/main/Multimodal_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install the required libraries:"
      ],
      "metadata": {
        "id": "M4MkOFDQYcxm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tH78Kx4BQETK"
      },
      "outputs": [],
      "source": [
        "! pip install \"unstructured[all-docs]\" pillow pydantic lxml matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get update"
      ],
      "metadata": {
        "id": "fMAP5JFCYppr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install poppler-utils"
      ],
      "metadata": {
        "id": "_7pQjef6a5CI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install tesseract-ocr"
      ],
      "metadata": {
        "id": "I65l9VNrcB7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install libtesseract-dev"
      ],
      "metadata": {
        "id": "U7GxLrovcHFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unstructured-pytesseract"
      ],
      "metadata": {
        "id": "uDoLMrMfcRbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_google_genai"
      ],
      "metadata": {
        "id": "nSPJ25NJ9yNU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Parsing / Data Extraction:"
      ],
      "metadata": {
        "id": "bqTigxgac1jA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from unstructured.partition.pdf import partition_pdf"
      ],
      "metadata": {
        "id": "MiG9Qd_xaq07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_pdf_elements=partition_pdf(\n",
        "    filename=\"/content/drive/MyDrive/Generative_AI_Advanced_NLP/Advance_NLP_Generative_AI/CODE/data/rag-for-nlp.pdf\",\n",
        "    strategy=\"hi_res\",\n",
        "    extract_images_in_pdf=True,\n",
        "    extract_image_block_types=[\"Image\",\"Table\"],\n",
        "    extract_image_block_to_payload=False,\n",
        "    extract_image_block_output_dir=\"/content/drive/MyDrive/Generative_AI_Advanced_NLP/Advance_NLP_Generative_AI/CODE/data/extracted_data_1\"\n",
        "    )"
      ],
      "metadata": {
        "id": "r4QOWrN3eq0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_pdf_elements"
      ],
      "metadata": {
        "id": "Bn0oEVyWfgtP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Header=[]\n",
        "Footer=[]\n",
        "Title=[]\n",
        "NarrativeText=[]\n",
        "Text=[]\n",
        "ListItem=[]\n",
        "Image=[]\n",
        "Table=[]\n",
        "\n",
        "for element in raw_pdf_elements:\n",
        "  if \"unstructured.documents.elements.Header\" in str(type(element)):\n",
        "            Header.append(str(element))\n",
        "  elif \"unstructured.documents.elements.Footer\" in str(type(element)):\n",
        "            Footer.append(str(element))\n",
        "  elif \"unstructured.documents.elements.Title\" in str(type(element)):\n",
        "            Title.append(str(element))\n",
        "  elif \"unstructured.documents.elements.NarrativeText\" in str(type(element)):\n",
        "            NarrativeText.append(str(element))\n",
        "  elif \"unstructured.documents.elements.Text\" in str(type(element)):\n",
        "            Text.append(str(element))\n",
        "  elif \"unstructured.documents.elements.ListItem\" in str(type(element)):\n",
        "            ListItem.append(str(element))\n",
        "  elif \"unstructured.documents.elements.Image\" in str(type(element)):\n",
        "            Image.append(str(element))\n",
        "  elif \"unstructured.documents.elements.Table\" in str(type(element)):\n",
        "            Table.append(str(element))"
      ],
      "metadata": {
        "id": "sVIsBLIIhi3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Header"
      ],
      "metadata": {
        "id": "8Yxa4SKGiZ8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Footer"
      ],
      "metadata": {
        "id": "f0Jp5UtkicPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ListItem"
      ],
      "metadata": {
        "id": "2ZXnbT3winpG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Title"
      ],
      "metadata": {
        "id": "Z36sy2EEivA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NarrativeText"
      ],
      "metadata": {
        "id": "J6PV88fmiqQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NarrativeText[0]"
      ],
      "metadata": {
        "id": "NXOnlKaii0cE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NarrativeText[1]"
      ],
      "metadata": {
        "id": "e8LcOVIfi09p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Text"
      ],
      "metadata": {
        "id": "pN_zs1UXi1_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Table"
      ],
      "metadata": {
        "id": "jZkyQq_ei9hW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Image"
      ],
      "metadata": {
        "id": "Xx2EUiqQi_DI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the Model and Embedding Model:"
      ],
      "metadata": {
        "id": "WAwsMc8ajDqT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "vw6OAhfWjBww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"GOOGLE_API_KEY\"]=GOOGLE_API_KEY"
      ],
      "metadata": {
        "id": "nnmE4idZ8w6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings"
      ],
      "metadata": {
        "id": "_Q3m0cFs8xV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(model_name):\n",
        "    if model_name == \"gemini-pro\": #To deal with Text\n",
        "        return ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\")\n",
        "    elif model_name == \"gemini-1.5-flash\": #To deal with Images\n",
        "        return ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
        "    elif model_name == \"embedding\": #To generate Embeddings\n",
        "        return GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported model name: {model_name}\")"
      ],
      "metadata": {
        "id": "Vn7eO1M98zgo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=load_model(\"gemini-1.5-flash\")"
      ],
      "metadata": {
        "id": "3kTZW_Cn85hg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a318080b"
      },
      "source": [
        "model_text=load_model(\"gemini-pro\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model_text.invoke(\"hi\")"
      ],
      "metadata": {
        "id": "Vsc6V_et991V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Exceeded the limit for Google Gemini, so proceeding with OpenAI:"
      ],
      "metadata": {
        "id": "5yZg30inHZQE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "OPENAI_API_KEY = userdata.get('OpenAI_API_Key')"
      ],
      "metadata": {
        "id": "_dqf52nDG9JW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
      ],
      "metadata": {
        "id": "kmrpxbNeG9Fn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-openai"
      ],
      "metadata": {
        "id": "lrwGr3AUG9Cd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_openai import OpenAIEmbeddings"
      ],
      "metadata": {
        "id": "6J2Be2SQG8_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(model_name):\n",
        "    if model_name == \"chat\": # To deal with Text\n",
        "        return ChatOpenAI(model=\"gpt-4o\")\n",
        "    elif model_name == \"vision\": # To deal with Images\n",
        "        return ChatOpenAI(model=\"gpt-4o\") # gpt-4o supports vision\n",
        "    elif model_name == \"embedding\": # To generate Embeddings\n",
        "        return OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported model name: {model_name}\")"
      ],
      "metadata": {
        "id": "kL_4NGJDHM91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(\"vision\")"
      ],
      "metadata": {
        "id": "Wj_6R8UCHM6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_text = load_model(\"chat\")"
      ],
      "metadata": {
        "id": "rABKXnAPHM3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_text.invoke(\"hi\")"
      ],
      "metadata": {
        "id": "a-7tgoagG87-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DATA INGESTION:"
      ],
      "metadata": {
        "id": "b9jIihmK-CE-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare the data for Vector Database:"
      ],
      "metadata": {
        "id": "4GO4SnO2-IVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary of the Text:"
      ],
      "metadata": {
        "id": "VNefvYKN-Lx-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_groq"
      ],
      "metadata": {
        "id": "tDPFbrm0-HuW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate"
      ],
      "metadata": {
        "id": "EEFDBaNPSits"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_text=\"\"\"You are an assistant tasked with summarizing text for retrieval. \\\n",
        "    These summaries will be embedded and used to retrieve the raw text elements. \\\n",
        "    Give a concise summary of the table or text that is well optimized for retrieval.text: {element} \"\"\""
      ],
      "metadata": {
        "id": "d7eUeVVNSihB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt=ChatPromptTemplate.from_template(prompt_text)"
      ],
      "metadata": {
        "id": "AMBomwnvSidY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model=load_model(\"gemini-pro\")"
      ],
      "metadata": {
        "id": "_qGV2RWgSl5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq"
      ],
      "metadata": {
        "id": "0HRTi4ZsSl2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GROQ_API_KEY = userdata.get('GROQ_API_KEY')\n",
        "os.environ[\"GROQ_API_KEY\"] = GROQ_API_KEY"
      ],
      "metadata": {
        "id": "nk9VlMl3WqbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "groq_model=ChatGroq(model=\"deepseek-r1-distill-llama-70b\",api_key=GROQ_API_KEY)"
      ],
      "metadata": {
        "id": "4BJxRlbZUMDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summarize_chain = {\"element\": lambda x: x} |prompt| groq_model | StrOutputParser()"
      ],
      "metadata": {
        "id": "E3_HAgGAUL43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(NarrativeText)"
      ],
      "metadata": {
        "id": "94FtqEQvUMrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(NarrativeText)"
      ],
      "metadata": {
        "id": "7CYSaxBaUNSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NarrativeText=NarrativeText[:10]"
      ],
      "metadata": {
        "id": "mP8_DuBPUSWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(NarrativeText)"
      ],
      "metadata": {
        "id": "mB0R3Ss5Ud8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_summary=[]\n",
        "text_summary=summarize_chain.batch(NarrativeText,{\"max_concurrency\": 5})"
      ],
      "metadata": {
        "id": "7r4Vlez7Ujwt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_summary"
      ],
      "metadata": {
        "id": "8XZSqDrdVTip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(text_summary[4])"
      ],
      "metadata": {
        "id": "uYF-HxRpYA6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "clean_text = re.sub(r\"<think>.*?</think>\\s*\", \"\", text_summary[4], flags=re.DOTALL)"
      ],
      "metadata": {
        "id": "U7KD2kQfYHVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_text"
      ],
      "metadata": {
        "id": "r7GZqQzKYNJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Summary of the Table:"
      ],
      "metadata": {
        "id": "MfU8ouSjYxBU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_text = \"\"\"You are an AI Assistant tasked with summarizing tables for retrieval. \\\n",
        "    These summaries will be embedded and used to retrieve the raw table elements. \\\n",
        "    Give a concise summary of the table that is well optimized for retrieval. Table:{element} \"\"\""
      ],
      "metadata": {
        "id": "e8WHnaGPYdUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_template(prompt_text)"
      ],
      "metadata": {
        "id": "a7YXHJbwY9lY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summarize_chain = {\"element\": lambda x: x} | prompt | groq_model | StrOutputParser()"
      ],
      "metadata": {
        "id": "xM6W3byZZA-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "table_summaries = []\n",
        "table_summaries = summarize_chain.batch(Table, {\"max_concurrency\": 5})"
      ],
      "metadata": {
        "id": "7yIrQjPlZClt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(table_summaries[0])"
      ],
      "metadata": {
        "id": "aTauyeggZFps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Summary of the Images:"
      ],
      "metadata": {
        "id": "MItMpFpZZSFN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import base64\n",
        "import os\n",
        "from langchain_core.messages import AIMessage, HumanMessage"
      ],
      "metadata": {
        "id": "o5OCYfHJZH_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_image(image_path):\n",
        "    with open(image_path, \"rb\") as image_file:\n",
        "        return base64.b64encode(image_file.read()).decode(\"utf-8\")"
      ],
      "metadata": {
        "id": "Q8RqfUpXZWIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_model = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")"
      ],
      "metadata": {
        "id": "REWzXmJVZnW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_model.invoke(\"hi\")"
      ],
      "metadata": {
        "id": "AwzFlQ6nZuWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def image_summarize(img_base64,prompt):\n",
        "    chat = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
        "    msg = chat.invoke(\n",
        "        [\n",
        "            HumanMessage(\n",
        "                content=[\n",
        "                    {\n",
        "                    \"type\": \"text\",\n",
        "                     \"text\": prompt\n",
        "                     }\n",
        "                    ,\n",
        "                    {\n",
        "                        \"type\": \"image_url\",\n",
        "                        \"image_url\": {\"url\": f\"data:image/jpeg;base64,{img_base64}\"},\n",
        "                    },\n",
        "                ]\n",
        "            )\n",
        "        ]\n",
        "    )\n",
        "    return msg.content"
      ],
      "metadata": {
        "id": "VqSeZh1QZzur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_img_summaries(path):\n",
        "    \"\"\"\n",
        "    Generate summaries and base64 encoded strings for images\n",
        "    path: Path to list of .jpg files extracted by Unstructured\n",
        "    \"\"\"\n",
        "\n",
        "    # Store base64 encoded images\n",
        "    img_base64_list = []\n",
        "\n",
        "    # Store image summaries\n",
        "    image_summaries = []\n",
        "\n",
        "    # Prompt\n",
        "    prompt = \"\"\"You are an assistant tasked with summarizing images for retrieval. \\\n",
        "    These summaries will be embedded and used to retrieve the raw image. \\\n",
        "    Give a concise summary of the image that is well optimized for retrieval.\"\"\"\n",
        "\n",
        "    # Apply to images\n",
        "    for img_file in sorted(os.listdir(path)):\n",
        "        if img_file.endswith(\".jpg\"):\n",
        "            img_path = os.path.join(path, img_file)\n",
        "            base64_image = encode_image(img_path)\n",
        "            img_base64_list.append(base64_image)\n",
        "            image_summaries.append(image_summarize(base64_image, prompt))\n",
        "\n",
        "\n",
        "    return img_base64_list, image_summaries"
      ],
      "metadata": {
        "id": "6r27CunyaIYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fpath=\"/content/drive/MyDrive/Generative_AI_Advanced_NLP/Advance_NLP_Generative_AI/CODE/data/extracted_data_1\""
      ],
      "metadata": {
        "id": "uFTo7gRSaMXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_base64_list, image_summaries=generate_img_summaries(fpath)"
      ],
      "metadata": {
        "id": "ofi4GoOqaX3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_base64_list"
      ],
      "metadata": {
        "id": "aNpv4nOoahNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_summaries"
      ],
      "metadata": {
        "id": "nRU-ueEabM5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_summaries[0]"
      ],
      "metadata": {
        "id": "28ByEg8CbQpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Store the Data inside the Vector Database and Create DATA RETRIEVER:"
      ],
      "metadata": {
        "id": "KPfcu3QZbZV1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VectorDatabase -> ChromaDB -> In Memory:"
      ],
      "metadata": {
        "id": "jolxODtyfB0D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-community"
      ],
      "metadata": {
        "id": "JUCYIK0ubUBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import uuid\n",
        "from langchain_core.documents import Document\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.storage import InMemoryStore\n",
        "from langchain.retrievers.multi_vector import MultiVectorRetriever"
      ],
      "metadata": {
        "id": "XhukeBeici-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_multi_vector_retriever(vectorstore, text_summaries, texts, table_summaries, tables, image_summaries, images):\n",
        "  store=InMemoryStore()\n",
        "  id_key=\"doc_id\"\n",
        "\n",
        "  retriever=MultiVectorRetriever(\n",
        "      vectorstore=vectorstore,\n",
        "      docstore=store,\n",
        "      id_key=id_key,\n",
        "  )\n",
        "\n",
        "  def add_documents(retriever, doc_summaries, doc_contents):\n",
        "\n",
        "      doc_ids = [str(uuid.uuid4()) for _ in doc_contents]\n",
        "\n",
        "      summary_docs = [\n",
        "              Document(page_content=summary, metadata={id_key: doc_ids[i]})\n",
        "\n",
        "              for i, summary in enumerate(doc_summaries)\n",
        "          ]\n",
        "\n",
        "      retriever.vectorstore.add_documents(summary_docs)\n",
        "      retriever.docstore.mset(list(zip(doc_ids, doc_contents)))\n",
        "\n",
        "\n",
        "  if text_summaries:\n",
        "        add_documents(retriever, text_summaries, texts)\n",
        "  if table_summaries:\n",
        "        add_documents(retriever, table_summaries, tables)\n",
        "  if image_summaries:\n",
        "        add_documents(retriever, image_summaries, images)\n",
        "\n",
        "  return retriever\n",
        "\n"
      ],
      "metadata": {
        "id": "n6oxImK1ctyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chromadb"
      ],
      "metadata": {
        "id": "RwP9OPfLebFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_model=load_model(\"embedding\")"
      ],
      "metadata": {
        "id": "drV8oLbzdpX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore=Chroma(collection_name=\"MMRAG\",embedding_function=embedding_model)"
      ],
      "metadata": {
        "id": "AcyonRWDeOVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever_multi_vector_img = create_multi_vector_retriever(\n",
        "    vectorstore,\n",
        "    text_summary,\n",
        "    NarrativeText,\n",
        "    table_summaries,\n",
        "    Table,\n",
        "    image_summaries,\n",
        "    img_base64_list,\n",
        ")"
      ],
      "metadata": {
        "id": "JfHBYeeDekkI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever_multi_vector_img"
      ],
      "metadata": {
        "id": "T-ZZO3Cme32X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cosine Similarity Search:"
      ],
      "metadata": {
        "id": "Dcv2iVaajPce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Why We combine a pre-trained retriever (Query Encoder + Document Index) with a pre-trained seq2seq model (Generator) and fine-tune end-to-end?\""
      ],
      "metadata": {
        "id": "qUTbC1Fye8XO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever_multi_vector_img.get_relevant_documents(query)"
      ],
      "metadata": {
        "id": "YuUswtJYgyVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever_multi_vector_img.invoke(query)"
      ],
      "metadata": {
        "id": "y5cf_WWUgyIj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Above this code we had Vector Store\n",
        "\n",
        "#### Below code for the Image Data Processing:"
      ],
      "metadata": {
        "id": "8-h_wPcOjmFR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import re\n",
        "from IPython.display import HTML, display\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "nQrT9x0agx5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_image_data(b64data):\n",
        "    image_signatures = {\n",
        "        b\"\\xFF\\xD8\\xFF\": \"jpg\",\n",
        "        b\"\\x89\\x50\\x4E\\x47\\x0D\\x0A\\x1A\\x0A\": \"png\",\n",
        "        b\"\\x47\\x49\\x46\\x38\": \"gif\",\n",
        "        b\"\\x52\\x49\\x46\\x46\": \"webp\",\n",
        "    }\n",
        "    try:\n",
        "        header = base64.b64decode(b64data)[:8]  # Decode and get the first 8 bytes\n",
        "        for sig, format in image_signatures.items():\n",
        "            if header.startswith(sig):\n",
        "                return True\n",
        "        return False\n",
        "    except Exception:\n",
        "        return False"
      ],
      "metadata": {
        "id": "R4jHi4org0DJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def looks_like_base64(sb):\n",
        "  return re.match(\"^[A-Za-z0-9+/]+[=]{0,2}$\", sb) is not None\n"
      ],
      "metadata": {
        "id": "uXr7EZ7lgz4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resize_base64_image(base64_string,size=(128,128)):\n",
        "  # Decode the Base64 string\n",
        "    img_data = base64.b64decode(base64_string)\n",
        "    img = Image.open(io.BytesIO(img_data))\n",
        "\n",
        "    # Resize the image\n",
        "    resized_img = img.resize(size, Image.LANCZOS)\n",
        "\n",
        "    # Save the resized image to a bytes buffer\n",
        "    buffered = io.BytesIO()\n",
        "    resized_img.save(buffered, format=img.format)\n",
        "\n",
        "    # Encode the resized image to Base64\n",
        "    return base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n"
      ],
      "metadata": {
        "id": "L41awC1kgzuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_image_text_types(docs):\n",
        "    \"\"\"\n",
        "    Split base64-encoded images and texts\n",
        "    \"\"\"\n",
        "    b64_images = []\n",
        "    texts = []\n",
        "\n",
        "    for doc in docs:\n",
        "        # Check if the document is of type Document and extract page_content if so\n",
        "        if isinstance(doc, Document):\n",
        "            doc = doc.page_content\n",
        "        if looks_like_base64(doc) and is_image_data(doc):\n",
        "            doc = resize_base64_image(doc, size=(1300, 600))\n",
        "            b64_images.append(doc)\n",
        "        else:\n",
        "            texts.append(doc)\n",
        "\n",
        "    return {\"images\": b64_images, \"texts\": texts}"
      ],
      "metadata": {
        "id": "_X8Asrw4gzkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def img_prompt_func(data_dict):\n",
        "  \"\"\"\n",
        "  Join the context into a single string\n",
        "  \"\"\"\n",
        "  print(data_dict)\n",
        "  formatted_texts = \"\\n\".join(data_dict[\"context\"][\"texts\"])\n",
        "  messages = []\n",
        "\n",
        "  # Adding image(s) to the messages if present\n",
        "  if data_dict[\"context\"][\"images\"]:\n",
        "      for image in data_dict[\"context\"][\"images\"]:\n",
        "          image_message = {\n",
        "              \"type\": \"image_url\",\n",
        "              \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image}\"},\n",
        "          }\n",
        "          messages.append(image_message)\n",
        "\n",
        "  # Adding the text for analysis\n",
        "  text_message = {\n",
        "      \"type\": \"text\",\n",
        "      \"text\": (\n",
        "          \"You are a helpful assistant.\\n\"\n",
        "          \"You will be given a mixed info(s) .\\n\"\n",
        "          \"Use this information to provide relevant information to the user question. \\n\"\n",
        "          f\"User-provided question: {data_dict['question']}\\n\\n\"\n",
        "          \"Text and / or tables:\\n\"\n",
        "          f\"{formatted_texts}\"\n",
        "      ),\n",
        "  }\n",
        "  messages.append(text_message)\n",
        "  return [HumanMessage(content=messages)]\n"
      ],
      "metadata": {
        "id": "L8hWop-RgzZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DATA GENERATION using Chaining:"
      ],
      "metadata": {
        "id": "owouB3mLg1Cc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnablePassthrough, RunnableLambda"
      ],
      "metadata": {
        "id": "a1O8g_Ieg4dz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def multi_modal_rag_chain(retriever):\n",
        "  chain=(\n",
        "      {\"context\":retriever | RunnableLambda(split_image_text_types),\n",
        "       \"question\": RunnablePassthrough()\n",
        "      }\n",
        "      | RunnableLambda(img_prompt_func)\n",
        "\n",
        "      |model\n",
        "      |StrOutputParser()\n",
        "  )\n",
        "\n",
        "  return chain"
      ],
      "metadata": {
        "id": "GD-5XuaFg7te"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain_multimodal_rag = multi_modal_rag_chain(retriever_multi_vector_img)"
      ],
      "metadata": {
        "id": "jK6XShG6hBX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query1=\"Explain any images / figures in the paper with Left: NQ performance as more documents are retrieved. Center: Retrieval recall performance\\\n",
        "in NQ. Right: MS-MARCO Bleu-1 and Rouge-L as more documents are retrieved.\""
      ],
      "metadata": {
        "id": "Y52dFpOfiCtu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain_multimodal_rag.invoke(query1)"
      ],
      "metadata": {
        "id": "GfJ5vQKHmTsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Why We combine a pre-trained retriever (Query Encoder + Document Index) with a pre-trained seq2seq model (Generator) and fine-tune end-to-end?\"\n"
      ],
      "metadata": {
        "id": "WWlw_f5TmYLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain_multimodal_rag.invoke(query)"
      ],
      "metadata": {
        "id": "gOcPFmQbmb5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X1siDBjvmhWN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}